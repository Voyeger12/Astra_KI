<div align="center">

# ğŸ”´ ASTRA AI

**Dein lokaler KI-Assistent â€” privat, schnell, intelligent.**

Moderne Desktop-App mit Echtzeit-Streaming, LangzeitgedÃ¤chtnis, Internet-Suche und automatischer GPU-Beschleunigung. LÃ¤uft komplett lokal Ã¼ber [Ollama](https://ollama.ai).

[![Python 3.13+](https://img.shields.io/badge/Python-3.13+-blue?logo=python&logoColor=white)](https://python.org)
[![PyQt6](https://img.shields.io/badge/UI-PyQt6-green?logo=qt)](https://pypi.org/project/PyQt6/)
[![Ollama](https://img.shields.io/badge/LLM-Ollama-black?logo=ollama)](https://ollama.ai)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

</div>

---

## âœ¨ Features

| Feature | Beschreibung |
|---------|-------------|
| ğŸš€ **Streaming-Antworten** | Text erscheint in Echtzeit, Chunk fÃ¼r Chunk |
| ğŸ§  **LangzeitgedÃ¤chtnis** | Merkt sich Namen, Vorlieben, Fakten Ã¼ber `[MERKEN:]`-Tags |
| ğŸ” **Internet-Suche** | DuckDuckGo-Integration fÃ¼r aktuelle Infos (Wetter, News, etc.) |
| ğŸ® **Auto GPU-Erkennung** | NVIDIA â†’ CUDA, AMD RDNA 3 â†’ ROCm, AMD RDNA 4 â†’ Vulkan, Intel â†’ Vulkan |
| ğŸ’¬ **Multi-Chat** | Unbegrenzte parallele Chat-Sessions mit separater History |
| ğŸ¨ **Rich Formatting** | Markdown-Rendering, Syntax-Highlighting, Code-BlÃ¶cke |
| âš™ï¸ **Konfigurierbar** | Modell, Temperatur, TextgrÃ¶ÃŸe, Theme Ã¼ber Settings-Dialog |
| ğŸ”’ **Sicherheit** | Input-Validation, Rate-Limiting, XSS/SQLi-Schutz |
| ğŸ“¦ **Standalone EXE** | Kann als Windows-EXE gebaut werden (keine Python-Installation nÃ¶tig) |

---

## ğŸš€ Quick Start

### Voraussetzungen

- **Python 3.13+**
- **Ollama** â€” [ollama.ai](https://ollama.ai) installieren
- Ein LLM-Modell herunterladen:
  ```bash
  ollama pull qwen2.5:14b    # Empfohlen (~9 GB)
  ```

### Installation

```bash
# Repository klonen
git clone https://github.com/Voyeger12/Astra_KI.git
cd Astra_KI

# Virtual Environment erstellen & aktivieren
python -m venv venv
.\venv\Scripts\activate        # Windows
# source venv/bin/activate     # Linux/Mac

# Dependencies installieren
pip install -r requirements.txt
```

### Starten

```bash
# Option 1: Direkt starten
python main.py

# Option 2: Ãœber das Start-Skript (Windows)
start.bat
```

> **Hinweis:** Ollama muss im Hintergrund laufen (`ollama serve` oder Ollama Desktop-App). ASTRA erkennt automatisch deine GPU und konfiguriert Ollama fÃ¼r maximale Performance.

---

## ğŸ® GPU-UnterstÃ¼tzung

ASTRA erkennt beim Start automatisch die GPU und setzt die optimalen Ollama-Einstellungen:

| GPU | Backend | Automatisch |
|-----|---------|-------------|
| NVIDIA (alle) | CUDA | âœ…  |
| AMD RX 7000 (RDNA 3) | ROCm | âœ… |
| AMD RX 9000 (RDNA 4) | Vulkan | âœ… |
| Intel Arc | Vulkan | âœ… |
| Keine dedizierte GPU | CPU | âœ… |

Die Statusleiste zeigt den aktiven Modus: `ğŸŸ¢ Online âš¡VULKAN` / `âš¡CUDA` / `ğŸ¢CPU`

---

## ğŸ“ Projektstruktur

```
ASTRA 2.0/
â”œâ”€â”€ main.py                         # Einstiegspunkt mit Crash-Recovery
â”œâ”€â”€ config.py                       # Zentrale Konfiguration
â”œâ”€â”€ start.bat                       # Windows-Launcher
â”œâ”€â”€ requirements.txt                # Python-Dependencies
â”œâ”€â”€ build_exe.py                    # PyInstaller â†’ Standalone EXE
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ database.py                 # SQLite mit WAL-Journaling
â”‚   â”œâ”€â”€ memory.py                   # LangzeitgedÃ¤chtnis (MERKEN-Tags)
â”‚   â”œâ”€â”€ ollama_client.py            # LLM-Streaming mit adaptiven Timeouts
â”‚   â”œâ”€â”€ gpu_detect.py               # Auto GPU-Erkennung & Konfiguration
â”‚   â”œâ”€â”€ logger.py                   # Strukturiertes Logging
â”‚   â”œâ”€â”€ utils.py                    # Security, Rate-Limiting, Suche
â”‚   â””â”€â”€ ui/
â”‚       â”œâ”€â”€ main_window.py          # Hauptfenster (PyQt6)
â”‚       â”œâ”€â”€ chat_display.py         # Chat-Bubbles & Streaming-Anzeige
â”‚       â”œâ”€â”€ rich_formatter.py       # Markdown â†’ HTML Rendering
â”‚       â”œâ”€â”€ settings_dialog.py      # Einstellungs-Dialog
â”‚       â”œâ”€â”€ settings_manager.py     # JSON-basierte Settings
â”‚       â”œâ”€â”€ workers.py              # QThread-Worker (LLM, Suche, Format)
â”‚       â”œâ”€â”€ styles.py               # Qt Stylesheets
â”‚       â””â”€â”€ colors.py               # Farbkonstanten
â”‚
â”œâ”€â”€ config/settings.json            # Benutzer-Einstellungen
â”œâ”€â”€ data/                           # SQLite-Datenbank & Backups
â”œâ”€â”€ logs/                           # Log-Dateien
â”œâ”€â”€ tests/                          # Test-Suite
â””â”€â”€ assets/                         # Icons & Assets
```

---

## âš™ï¸ Konfiguration

### Settings-Dialog (in der App)

Ãœber das Zahnrad-Icon in der UI einstellbar:
- **Modell** â€” LLM-Modell wechseln (z.B. qwen2.5:14b, llama3.2, mistral)
- **Temperatur** â€” KreativitÃ¤t der Antworten (0.0 = prÃ¤zise, 1.0 = kreativ)
- **TextgrÃ¶ÃŸe** â€” SchriftgrÃ¶ÃŸe im Chat
- **Internet-Suche** â€” Ein/Aus
- **GedÃ¤chtnis** â€” Ein/Aus

### config.py (fÃ¼r Entwickler)

```python
OLLAMA_HOST = "http://localhost:11434"
DEFAULT_MODEL = "qwen2.5:14b"

# Performance-Tuning
OLLAMA_PERFORMANCE = {
    "keep_alive": "30m",    # Modell im VRAM behalten
    "num_ctx": 4096,        # Context-Window
    "num_batch": 512,       # Batch-GrÃ¶ÃŸe
}
MAX_CHAT_HISTORY_MESSAGES = 20  # Kontext-Limit
```

---

## ğŸ”§ Troubleshooting

| Problem | LÃ¶sung |
|---------|--------|
| ğŸ”´ Offline-Status | Ollama starten: `ollama serve` |
| ğŸ¢ Langsame Antworten | GPU-Backend in Statusleiste prÃ¼fen â€” `CPU` = keine GPU-Beschleunigung |
| Kein Modell verfÃ¼gbar | `ollama pull qwen2.5:14b` |
| ModuleNotFoundError | `pip install -r requirements.txt` |
| Database locked | App neustarten |
| Suche liefert nichts | Internet-Verbindung prÃ¼fen |

---

## ğŸ“¦ Build (Windows EXE)

```bash
python build_exe.py
# Ergebnis: dist/ASTRA AI.exe (~150 MB, standalone)
```

---

## ğŸ›¡ï¸ Sicherheit

- **Input-Validation** â€” XSS- und SQL-Injection-Schutz
- **Rate-Limiting** â€” Max. 30 Nachrichten pro Minute
- **SQLite WAL** â€” Crash-sichere Datenbank
- **Graceful Recovery** â€” Automatischer Neuversuch bei Fehlern (3x Retry)

---

## ğŸ“„ Lizenz

MIT License â€” Frei zur Verwendung und Modifikation.
