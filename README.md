# ASTRA v0.2 - AI Chat Assistant

**Production-Ready** Intelligente Chat-Anwendung mit lokalem LLM (Ollama), Live Internet-Suche, Auto-Learning und LangzeitgedÃ¤chtnis.

## v0.2 Status: âœ… PRODUCTION READY

- âœ¨ **Internet-Suche**: DuckDuckGo Integration (asynchron, non-blocking)
- ðŸš€ **Auto-Learning**: Intelligentes Memory-System (Namen, Ort, Interessen)
- ðŸ“Š **Streaming LLM**: Text kommt in Echtzeit
- âš¡ **Performance**: Nachricht sofort sichtbar, <1s UI-Response
- ðŸ” **Sicherheit**: Input-Validation, Rate-Limiting, Database-Integrity
- ðŸ§ª **Getestet**: 26/26 Tests âœ… (Database, Memory, Search, Utils)

---

## Installation

### Voraussetzungen

- **Python 3.8+** (getestet mit 3.11)
- **Ollama**: https://ollama.ai (installiert und laufen gelassen)
- **Ein Model**: z.B. `ollama pull qwen2.5:14b` (empfohlen, ~14GB)
  - Alternativen: dolphin-llama3:latest, llama3.2
- **Internet**: FÃ¼r Web-Suche Feature (optional deaktivierbar)

### Quick Start

**Windows:**
```bash
# 1. Virtual Environment
python -m venv venv
.\venv\Scripts\activate

# 2. Dependencies
pip install -r requirements.txt

# 3. Ollama starten (separates Terminal ZUERST!)
ollama serve

# 4. App starten (im ersten Terminal)
python main.py
```

**Linux/Mac:**
```bash
# 1. Virtual Environment
python3 -m venv venv
source venv/bin/activate

# 2. Dependencies  
pip install -r requirements.txt

# 3. Ollama (separates Terminal)
ollama serve

# 4. App
python main.py
```

### Oder direkt aus Windows EXE
```bash
python build_exe.py        # Erstellt standalone EXE
# Dann: dist/ASTRA\ AI.exe doppelklick
```

---

## Features

### ðŸ” Internet-Suche (v0.2)

**Intelligente Web-Recherche mit DuckDuckGo:**
- âœ… Automatische Aktivierung fÃ¼r Info-Fragen
- âœ… Asynchron/Non-Blocking (UI bleibt fluent)
- âœ… Intelligente Zusammenfassung
- âœ… Fallback bei Fehler

**Beispiel:**
```
Du: "Wie ist das Wetter in MÃ¼nchen?"
ASTRA: "Das Wetter in MÃ¼nchen ist derzeit sonnig mit 12Â°C..."
       (mit echten aktuellen Daten von DuckDuckGo)
```

### ðŸ’¾ Auto-Learning Memory

**Intelligente Informationen-Erfassung:**
- ðŸ‘¤ Namen: "Ich heiÃŸe Duncan"
- ðŸ“ Orte: "Ich bin in Essen"
- ðŸŽ‚ Alter: "Ich bin 28 Jahre alt"
- â¤ï¸ Interessen: "Ich mag Programmierung"

### ðŸ“± Multi-Chat Sessions
- Unbegrenzte parallele Chats
- Jeder Chat mit separater History
- Auto-Delete & Rename

---

## Testing

```bash
# Komplette Suite (26 Tests, ~10s) âœ… ALL PASSING
python tests/test_suite.py

# Mit Details & Interaktiv
python tests/runner.py
```

**Test Coverage:**
- âœ… Database (4 Tests)
- âœ… Memory & Auto-Learning (8 Tests) 
- âœ… Memory System Prompt (2 Tests)
- âœ… Text Utilities (2 Tests)
- âœ… Search Logic (8 Tests)
- **Total: 26/26 PASSING**

---

## Projekt-Struktur

```
ðŸ“ ASTRA 2.0
â”œâ”€â”€ main.py                    Hauptprogramm
â”œâ”€â”€ config.py                  Zentrale Konfiguration
â”œâ”€â”€ persona.txt                KI Persona
â”œâ”€â”€ requirements.txt           Dependencies
â”œâ”€â”€ build_exe.py               PyInstaller Builder
â”‚
â”œâ”€â”€ ðŸ“ modules/                Core-Engine
â”‚   â”œâ”€â”€ database.py            SQLite + WAL
â”‚   â”œâ”€â”€ memory.py              Auto-Learning
â”‚   â”œâ”€â”€ ollama_client.py       LLM Integration
â”‚   â”œâ”€â”€ utils.py               Security, Search
â”‚   â””â”€â”€ ðŸ“ ui/                 PyQt6 Interface
â”‚
â”œâ”€â”€ ðŸ“ tests/                  26 Tests âœ…
â”œâ”€â”€ ðŸ“ data/                   Datenbank & Backups
â”œâ”€â”€ ðŸ“ logs/                   Logging Output
â””â”€â”€ ðŸ“ config/                 Settings (JSON)
```

---

## Sicherheit & Robustheit

| Feature | Status |
|---------|--------|
| Input Validation | âœ… XSS & SQLi Protection |
| Rate-Limiting | âœ… Max 30 Messages/Minute |
| Database | âœ… WAL-Journaling, Concurrent Safe |
| Error Handling | âœ… Graceful Recovery, Retry 3x |
| Async Safety | âœ… Thread-safe Design |
| Logging | âœ… Zentral strukturiert |

---

## Konfiguration

### config.py
```python
OLLAMA_HOST = "http://localhost:11434"
DEFAULT_MODEL = "qwen2.5:14b"
MAX_MESSAGE_LENGTH = 10000
INTERNET_SEARCH_ENABLED = True
```

### config/settings.json (UI-Persistiert)
```json
{
  "text_size": 12,
  "selected_model": "qwen2.5:14b",
  "temperature": 0.77,
  "search_enabled": true,
  "memory_enabled": true
}
```

---

## Troubleshooting

| Problem | LÃ¶sung |
|---------|--------|
| "ðŸ”´ Offline" Status | `ollama serve` in separatem Terminal |
| ModuleNotFoundError: PyQt6 | `pip install PyQt6>=6.6.0` |
| database is locked | App neustarten |
| Message nicht sichtbar | `taskkill /F /IM python.exe` |
| Search hÃ¤ngt | Internet-Verbindung prÃ¼fen |
| Model zu langsam | `ollama pull llama3.2` (kleiner/schneller) |

---

## Build & Distribution

### Windows EXE
```bash
python build_exe.py   # Erstellt: dist/ASTRA AI.exe (~150MB)
```

**Includes:**
- PyQt6 UI âœ…
- Internet-Search âœ…  
- Ollama Support âœ…
- Keine Python-Installation auf Ziel-PC nÃ¶tig

### GitHub Release
```bash
git tag v0.2
git push origin v0.2
# Upload: dist/ASTRA AI.exe
```

---

## Roadmap (v0.3+)

- [ ] Speech-to-Text
- [ ] Text-to-Speech  
- [ ] More Models (GPT-4, Claude API)
- [ ] Learning Optimization
- [ ] Dark Mode Toggle

---

## Lizenz

MIT License - Frei zur Verwendung und Modifikation.

---

**Status:** âœ… v0.2 Production Ready | ðŸ§ª 26/26 Tests âœ… | âš¡ Optimized & Stable
